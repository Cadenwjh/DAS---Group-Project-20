Combine with the the Explanatory Data Analysis File, this section is the next one.

---
title: "Group 20"
format: 
  html:
    embed-resources: true
    code-tools: true
  pdf: default
editor_options: 
  chunk_output_type: console
execute:
  echo: false
  eval: true
  warning: false
  message: false
---

```{r}
library(dplyr)
library(ggplot2)
library(faraway)
library(gridExtra)
library(MASS)
library(plyr)
library(dplyr)
library(sjPlot)
library(AER)
```

# Formal Data Analysis

In this section, several formal statistical models will be conducted using a Generalized Model Analysis to infer the relationships between variables.

## A. Model Fitting

***This should be conducted on the EDA section, so after combined it, this should be removed***.

```{r}
#| echo: FALSE
#| results: 'hide'
data <- read.csv('dataset20.csv', stringsAsFactors = FALSE)
str(data)

data$animal_type <- as.factor(data$animal_type)
data$intake_type <- as.factor(data$intake_type)
data$chip_status <- as.factor(data$chip_status)
```

### A.1 Poisson Model

Since the response variable represents the count data, the Poisson regression model is a starting point because it ise the simplest model for the type of the data. It was conducted by this result:

```{r}
#| echo: false
glm_poisson <- glm(time_at_shelter ~ animal_type + month + year + intake_type + chip_status, family = "poisson", data = data)
summary(glm_poisson)
```

Before presenting and interpreting the derived equation from our GLM analysis, it is important to note that validating the model is underlying assumptions is a critical step. Ensuring the assumptions hold true bolsters the reliability of our findings. Here's the equation based on the initial analysis, subject to further validation:

$$
\begin{aligned}
\log(\text{Expected Count of Time at Shelter}) &= 578.124443 \\
&+ 2.765699 \times \text{AnimalTypeCat} \\
&+ 2.875463 \times \text{AnimalTypeDog} \\
&+ 2.609189 \times \text{AnimalTypeWildlife} \\
&- 0.030088 \times \text{Month} \\
&- 0.286813 \times \text{Year} \\
&- 0.735566 \times \text{IntakeTypeOwnerSurrender} \\
&- 0.517652 \times \text{IntakeTypeStray} \\
&- 0.014802 \times \text{ChipStatusScanNoChip} \\
&- 0.472796 \times \text{ChipStatusUnableToScan}
\end{aligned}
$$

where,

-   $\text{AnimalTypeCat}$, $\text{AnimalTypeDog}$, $\text{AnimalTypeWildlife}$ are indicator variables for the animal types, taking the value 1 if the condition is true and 0 otherwise with the baseline category $\text{AnimalTypeBird}$.

-   $\text{Month}$ and $\text{Year}$ are numerical variables representing the month and year of intake.

-   $\text{IntakeTypeOwnerSurrender}$ and $\text{IntakeTypeStray}$ are indicator variables for the intake types, taking the value 1 if the condition is true and 0 otherwise with the baseline category $\text{IntakeTypeConfiscated}$.

-   $\text{ChipStatusScanNoChip}$ and $\text{ChipStatusUnableToScan}$ are indicator variables for the intake types, taking the value 1 if the condition is true and 0 otherwise with the baseline category $\text{ChipStatusScanChip}$.

The significance of a Generalized Linear Model (GLM) can be assessed by examining the p-values associated with the coefficients of the model, which indicate the strength of evidence against the null hypothesis that the corresponding coefficients are equal to zero. A small p-value (in this case, compared to the significance level 0.05) indicates strong evidence against the null hypothesis, suggesting that it is unlikely to observe such a significant effect if the predictor really had no impact on the response variable. Conversely, a large p-value suggests insufficient evidence to reject the null hypothesis, indicating that the predictor may not have a significant effect on the response variable. Meanwhile derived from the model, $\text{AnimalTypeCat}$, $\text{AnimalTypeDog}$, $\text{AnimalTypeWildLife}$, $\text{Month}$, $\text{Year}$, $\text{IntakeTypeSurrenderOwnerSurrender}$, $\text{IntakeTypeStray}$, and $\text{ChipStatusUnableToScan}$ variables are significant predictors of the time an animal spends in the shelter. On the other hand, the presence of a microchip, unless it cannot be scanned ($\text{ChipStatusScanNoChip}$ variable), does not significantly affect shelter time.

#### Model Diagnostics and Assumptions Checking

The analysis utilized a Poisson regression model to investigate the impact of factors such as, including $\text{AnimalType}$, $\text{Month}$, $\text{Year}$, $\text{IntakeType}$, and $\text{ChipStatus}$ on the duration of stay in a shelter. To ensure the robustness of our model, we conducted a thorough diagnostic evaluation using several methods. We checked the dispersion parameter to evaluate the presence of overdispersion, which would violate the Poisson assumption of equal mean and variance. We also examined the deviance to assess the model's goodness-of-fit, with a value near the degrees of freedom indicating a well-fitting model. Additionally, we conducted a residual analysis, including plotting residuals against fitted values and creating Q-Q plots of standardized residuals, to detect any systematic patterns that might indicate model misspecification. Together, these diagnostics help validate our model and confirm the reliability of our conclusions.

**Dispersion**

In a Poisson generalized linear model (GLM), the dispersion parameter is assumed to be fixed at 1. This assumption is crucial because the Poisson distribution is characterized by its mean being equal to its variance, a property known as *equidispersion*. When the observed variance is greater than the mean, the data exhibit *overdispersion*. This is more common in practice and can arise from various sources, such as unobserved heterogeneity among observations, excess zeros, or violations of the Poisson model's assumptions (such as events not occurring independently).

Then, the hypothesis being tested relates to the dispersion of the data with a significance level 5% is stated below:

-   Null Hypothesis (H0):

    The null hypothesis posits that the true dispersion parameter equals 1. This means the data follow a Poisson distribution accurately, where the mean and variance of the count data are equal (equidispersion). The model is adequately specified, and there's no extra variability in the data beyond what the Poisson model accounts for.

-   Alternative Hypothesis (Ha):

    The alternative hypothesis suggests that the true dispersion parameter is greater than 1, indicating overdispersion in the data. Overdispersion occurs when the observed variance in the count data is greater than what the Poisson model would predict based on the mean.

```{r}
dispersiontest(glm_poisson)
```

```{r}
#| echo: false
#| fig-cap: Residuals Plot for Assessing Dispersion in Poisson Regression
#| label: fig-resid
#| fig-align: center
#| fig-width: 3.5
#| fig-height: 3.5

ggplot(glm_poisson, aes(x = log(fitted(glm_poisson)), y = log((data$time_at_shelter - fitted(glm_poisson))^2))) + geom_point(col = "#DD7A65") + geom_abline(slope = 1, intercept = 0, col = "#F58B05", size = 1) + ylab(expression((y-hat(mu))^2)) + xlab(expression(hat(mu)))
```

Interpretation:

-   p-value is extremely small, below the significance level, which indicates that the result is highly statistically significant. Hence, this supports the alternative hypothesis that the true dispersion is greater than 1.

-   The sample estimated - dispersion is 8.52551 which is substantially greater than 1, indicating a significant level of overdispersion in the data.

-   Meanwhile, a common way to assess dispersion in a Poisson model is through a plot of the residuals which is displayed in @fig-resid. It suggests that as the predicted values increase, the variance of the residuals also increases (as indicated by the upward trend), which is a classic sign of overdispersion. Overdispersion is when the variance is greater than the mean, which often occurs with count data.

-   Given this evidence of overdispersion, it would be prudent to consider alternative models that can accommodate the extra variability, such as a Negative Binomial regression model which will be conducted later.

**Deviance:**

Deviance is used to quantify the difference between a fitted model and a perfect model (a saturated model that fits the data exactly). The deviance essentially quantifies the discrepancy between the observed data and the values predicted by the model under the assumption that the model is correct. A lower deviance indicates a better fit of the model to the data.

Hence, based on the generated model result, we got:

-   Null Deviance: this represents the goodness of fit of a model that includes only the intercept (no predictors). It is 10754 on 1464 degrees of freedom.

-   Residual Deviance: This is the goodness of fit of the model that includes predictors ($\text{AnimalType}$, $\text{Month}$, $\text{Year}$, $\text{IntakeType}$, and $\text{ChipStatus}$). It is 10266 on 1455 degrees of freedom.

The residual deviance is used to assess the fit of the model to the data. For a well-fitting model, the residual deviance should be close to the degrees of freedom (relatively low). Here, the residual deviance (10266) is quite high compared to the Chi-square distribution with the 1455 - degrees of freedom, which might indicate that the model does not fit the data perfectly. This could be a sign of overdispersion or that the model is missing some key explanatory variables.

**Residuals Analysis**

-   Plotting residuals vs. fitted values

    ```{r}
    #| echo: false
    #| fig-cap: Residuals vs. Fitted Values Plot for Poissron Regression Model
    #| label: fig-resid_analysis1
    #| fig-align: center
    #| fig-width: 4
    #| fig-height: 3

    plot(glm_poisson$fitted.values, residuals(glm_poisson, type = "deviance"), 
         xlab = "Fitted Values", ylab = "Deviance Residuals", pch = 20)
    abline(h = 0, col = "red")
    ```

    Based on the plot @fig-resid_analysis1 The residuals plot here shows that as the fitted values increase, the spread of the residuals also increases. The increase in the spread of residuals as the fitted values increase suggests that the variance of the residuals is not constant. This pattern indicates potential overdispersion in the data where the variance exceeds the mean.

-   Scale location plot (spread vs. level plot)

    ```{r}
    #| echo: false
    #| fig-cap: Scale-Location Plot (Spread vs. Level Plot)
    #| label: fig-resid_analysis2
    #| fig-align: center
    #| fig-width: 4
    #| fig-height: 3

    plot(glm_poisson$fitted.values, sqrt(abs(residuals(glm_poisson, type = "pearson"))), xlab = "Fitted Values", ylab = "√|Standardized Pearson Residuals|")
    ```

    The plot @fig-resid_analysis2 represents a scatter plot of the square root of the absolute standardized Pearson residuals versus the fitted values from a Generalized Linear Model (GLM). It will give the information about the move of the variance across different levels of the mean, making it easier to see whether there is a consistent spread of residuals across all counts or whether the spread increases with the count (which would indicate overdispersion). Meanwhile, we can see that there is a concentration of residuals around the lower fitted values, with residuals spreading out as the fitted values increase. It reveals several points that stand out from the main cluster, particularly at the mid-range of fitted values, indicating potential outliers or influential observations. This pattern suggests possible overdispersion in the data and will be advisable to consider model alternatives like the negative binomial regression.

-   Residual vs. leverage

    ```{r}
    #| echo: false
    #| fig-cap: Residuals vs. Leverage Plot
    #| label: fig-resid_analysis3
    #| fig-align: center
    #| fig-width: 4
    #| fig-height: 3

    plot(hatvalues(glm_poisson), residuals(glm_poisson, type = "pearson"), xlab = "Leverage", ylab = "Pearson Residuals")
    abline(h = 0, col = "red")
    ```

    Most of the data points cluster at the left side of the plot, suggesting that these observations have lower leverage and smaller residuals, shown by the plot @fig-resid_analysis3. Then, they don't have an undue influence on the model which seems the model fits well for the majority of the data. However, the presence of points with high residuals and high leverage in the right side suggests there are some exceptions where the model's fit is not as good. Hence, it would be that while the model appears to provide a good fit for most of the data, there are specific observations that require further investigation to ensure the model's robustness and to potentially improve its accuracy.

When diagnostic plots provide different insights, it is crucial to consider the overall evidence and the specific research context. If overdispersion is a consistent concern across multiple diagnostics (like the Residuals vs. Fitted Values Plot and the Scale-Location Plot), it often outweighs indications from other plots that the model might be adequate for most data points. Therefore, even if the Residuals vs. Leverage Plot suggests the model is mostly fitting well, the evidence of overdispersion from the other plots is a strong indicator that the Poisson model might not be the best choice. Exploring alternative models like the Negative Binomial, which can accommodate overdispersion, is likely a prudent step to improve model fit and ensure more reliable inference from the model.

\clearpage

### A.2 Negative Binomial Model

It will be conducted the Negative Binomial Model which is a good alternative model when the assumption of equidispersion (mean equals variance) in Poisson regression doesn't hold. The result was shown by:

```{r}
glm_nb <- glm.nb(time_at_shelter ~ animal_type + month + year + intake_type + chip_status, data = data)
summary(glm_nb)
```

$$
\begin{aligned}
\log(\text{Expected Count of Time at Shelter}) = 
&\ 620.40667 \\
&+ 2.76946 \times \text{AnimalTypeCat} \\
&+ 2.86336 \times \text{AnimalTypeDog} \\
&+ 2.58130 \times \text{AnimalTypeWildLife} \\
&- 0.03283 \times \text{Month} \\
&- 0.30775 \times \text{Year} \\
&- 0.75490 \times \text{IntakeTypeOwnerSurrender} \\
&- 0.55483 \times \text{IntakeTypeOwnerStrayStary} \\
&+ 0.01468 \times \text{ChipStatusScanNoChip} \\
&- 0.47382 \times \text{ChipStatusUnableToScan}
\end{aligned}
$$

where,

-   $\text{AnimalTypeCat}$, $\text{AnimalTypeDog}$, $\text{AnimalTypeWildlife}$ are indicator variables for the animal types, taking the value 1 if the condition is true and 0 otherwise with the baseline category $\text{AnimalTypeBird}$.

-   $\text{Month}$ and $\text{Year}$ are numerical variables representing the month and year of intake.

-   $\text{IntakeTypeOwnerSurrender}$ and $\text{IntakeTypeStray}$ are indicator variables for the intake types, taking the value 1 if the condition is true and 0 otherwise with the baseline category $\text{IntakeTypeConfiscated}$.

-   $\text{ChipStatusScanNoChip}$ and $\text{ChipStatusUnableToScan}$ are indicator variables for the intake types, taking the value 1 if the condition is true and 0 otherwise with the baseline category $\text{ChipStatusScanChip}$.

Based on the result, $\text{AnimalTypeCat}$, $\text{AnimalTypeDog}$, $\text{AnimalTypeWildLife}$, $\text{Month}$, $\text{Year}$, $\text{IntakeTypeSurrenderOwnerSurrender}$, $\text{IntakeTypeStray}$, and $\text{ChipStatusUnableToScan}$ variables significantly affect the time an animal spends in the shelter, while $\text{ChipStatusScanNoChip}$ variable does not have a significantly affect. In light of these findings, model selection techniques, particularly the comparison of Akaike Information Criterion (AIC) values, will be employed in subsequent analyses to refine the model further.

#### Model Diagnostics and Assumptions Checking

To ensure the reliability and validity of our Negative Binomial regression model findings, it is imperative to rigorously examine the underlying assumptions through a series of diagnostic checks.

**Overdispersion Check**

Attained from the model summary, we can draw the result that the parameter $\text{Theta}$: 0.7625 along with a relatively small standard error $\text{Std.Err}$: 0.0348 which indicates that the model has identified and is accounting for overdispersion in the data. It suggest that the Negative Binomial model is a suitable choice for the data, given the presence of overdispersion as a positive outcome in terms of assumptions checking for the model.

**Residual Deviance**

Deviance in GLMs is a measure of the goodness-of-fit of a model. It is based on the likelihood function and compares two models between the fitted model and a reference model. The lower the deviance, the closer the fitted model is to the reference model in terms of likelihood. Comparing the residual deviance to the degrees of freedom helps assess if the fitted model is adequately fitting the data without overfitting. If the residual deviance is close to the degrees of freedom for the fitted model, it suggests that the model is adequately fitting the data.

Then, in the model summary, attained the Residual Deviance: 1687.1 with the 1455 degrees of freedom and the Null Deviance: 1743.0 with the 1464 degrees of freedom, this shows how much better the model fits the data compared to the model with only the intercept. Meanwhile, the residual deviance is relatively close to the degrees of freedom suggests that the model is doing a reasonably good job of fitting the data.

**Residual Analysis**

In evaluating the adequacy of our Negative Binomial regression model, a series of residual diagnostic plots were examined, including Residuals vs Fitted, Normal Q-Q, Scale-Location, and Residuals vs Leverage, each offering insights into different aspects of model fit and underlying assumptions.

```{r}
#| echo: false
#| fig-cap: Residuals vs. Fitted Values Plot
#| label: fig-BN
#| fig-align: center
#| fig-width: 4
#| fig-height: 3

par(mfrow = c(1,1))
plot(glm_nb)
```

-   Residuals vs. Fitted Values Plot

    ```{r}
    par(mfrow = c(2,2))
    plot(glm_nb)
    ```

    ```{r}
    #| echo: false
    #| fig-cap: Residuals vs. Fitted Values Plot
    #| label: fig-BN1
    #| fig-align: center
    #| fig-width: 4
    #| fig-height: 3

    plot(glm_nb, which = 1)
    ```

    Shown in the plot @fig-BN1, the residuals seem to increase slightly in variance with larger fitted values, suggesting potential mild heteroscedasticity. However, since this is count data being modeled with a Negative Binomial regression, some of this is to be expected and the model accounts for it. There may be some potential outliers, but their influence would need further investigation, possibly with additional diagnostics like Cook's distance.

-   Normal Q-Q Plot:

    ```{r}
    #| echo: false
    #| fig-cap: Normal Q-Q Plot
    #| label: fig-BN2
    #| fig-align: center
    #| fig-width: 4
    #| fig-height: 3

    plot(glm_nb, which = 2)
    ```

    In the Q-Q plot @fig-BN2, the residuals deviate from the line at both ends, indicating that the residuals might not be following a normal distribution, which is a common issue for count data and is often the reason for using a Negative Binomial model instead of Poisson.

-   Scale-Location Plot

    ```{r}
    #| echo: false
    #| fig-cap: Scale-Location Plot
    #| label: fig-BN3
    #| fig-align: center
    #| fig-width: 4
    #| fig-height: 3

    plot(glm_nb, which = 3)
    ```

    The red line, captured on the plot @fig-BN3, shows some fluctuation but does not exhibit a clear or strong trend which indicates potential mild heteroscedasticity. The spread of residuals at the higher end of predicted values suggests that the variance of residuals might be slightly larger for animals predicted to have a longer stay in the shelter. There are a few points that stand away from the bulk of the data, which could be outliers or extreme values. These might be worth investigating further as they could have a disproportionate impact on the model.

-   Residuals vs. Leverage

    ```{r}
    #| echo: false
    #| fig-cap: Residuals vs. Leverage
    #| label: fig-BN4
    #| fig-align: center
    #| fig-width: 4
    #| fig-height: 3

    plot(glm_nb, which = 4)
    ```

    Observations with higher Cook's distance values are worth examining because they might be outliers or influential data points that could unduly affect the model's coefficients, predictions, and overall fit. Based on the plot @fig-BN4, most observations have a Cook's distance close to zero, indicating they have little influence on the regression model. However, there are a few observations, labeled with their observation numbers, that stand out with higher Cook's distance values yet not necessarily a problem for the fitting model.

**Summary of Model Diagnostic**

In conclusion, the model appears to perform well in terms of fitting the central tendency and dispersion of the data, as suggested by the lack of systematic patterns in residuals and the appropriate handling of overdispersion.

## B. Model Selection

Considering $\text{ChipStatusScanNoChip}$ variable is not significant based on the summary model, we employed a backward elimination process guided by the Akaike Information Criterion (AIC) to identify the most parsimonious model that adequately explains the variation in the time animals spend at the shelter. This approach systematically removes the least significant predictors from the full model, optimizing the balance between model complexity and fit to the data.

```{r}
#Initial Model
glm_nb <- glm.nb(time_at_shelter ~ animal_type + month + year + intake_type + chip_status, data = data)
#Selected Model
selected_nb <- stepAIC(glm_nb, direction = "backward")
```

The output of the stepAIC function with the direction set to "backward" suggests that the most parsimonious model according to the Akaike Information Criterion (AIC) is actually the initial model. The result of $\text{<none>}$ : 8350.4 as the lowest AIC indicates to remove no predictors from the current model.

## C. Model Refinement

# Conclusion
